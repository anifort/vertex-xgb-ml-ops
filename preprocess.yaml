name: Split data
inputs:
- {name: data_path, type: String}
outputs:
- {name: data_out_x_train, type: Dataset}
- {name: data_out_x_test, type: Dataset}
- {name: data_out_y_train, type: Dataset}
- {name: data_out_y_test, type: Dataset}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'argparse' 'pandas' 'xgboost' 'numpy' 'sklearn' 'fsspec' 'gcsfs' 'kfp==1.8.9' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef split_data(\n    data_out_x_train: Output[Dataset],\n    data_out_x_test:\
      \ Output[Dataset],\n    data_out_y_train: Output[Dataset],\n    data_out_y_test:\
      \ Output[Dataset],\n    data_path: str,\n):\n    import pandas as pd\n    import\
      \ xgboost as xgb\n    import numpy as np\n    import collections\n    import\
      \ sklearn\n    from google.cloud import storage # test\n    from sklearn.model_selection\
      \ import train_test_split\n    from sklearn.utils import shuffle\n\n    ###\
      \ Import data ###\n    COLUMN_NAMES = collections.OrderedDict({\n        'as_of_year':\
      \ np.int16,\n        'agency_code': 'category',\n        'loan_type': 'category',\n\
      \        'property_type': 'category',\n        'loan_purpose': 'category',\n\
      \        'occupancy': np.int8,\n        'loan_amt_thousands': np.float64,\n\
      \        'preapproval': 'category',\n        'county_code': np.float64,\n  \
      \      'applicant_income_thousands': np.float64,\n        'purchaser_type':\
      \ 'category',\n        'hoepa_status': 'category',\n        'lien_status': 'category',\n\
      \        'population': np.float64,\n        'ffiec_median_fam_income': np.float64,\n\
      \        'tract_to_msa_income_pct': np.float64,\n        'num_owner_occupied_units':\
      \ np.float64,\n        'num_1_to_4_family_units': np.float64,\n        'approved':\
      \ np.int8\n    })\n\n    data = pd.read_csv(data_path, index_col=False, dtype=COLUMN_NAMES)\n\
      \n    ### Feature engineering ###\n    data = data.dropna()\n    data = data[0:100]\n\
      \    data = shuffle(data, random_state=2)\n\n    labels = data['approved'].values\n\
      \    data = data.drop(columns=['approved'])\n\n    dummy_columns = list(data.dtypes[data.dtypes\
      \ == 'category'].index)\n    data = pd.get_dummies(data, columns=dummy_columns)\n\
      \n    x,y = data.values,labels\n    x_train,x_test,y_train,y_test = train_test_split(x,y)\n\
      \n    ### Export data as artifact ###\n    pd.DataFrame(x_train).to_csv(data_out_x_train.path,\
      \ index=False, header=False)  \n    pd.DataFrame(y_train).to_csv(data_out_y_train.path,\
      \ index=False, header=False)  \n    pd.DataFrame(x_test).to_csv(data_out_x_test.path,\
      \ index=False, header=False)  \n    pd.DataFrame(y_test).to_csv(data_out_y_test.path,\
      \ index=False, header=False)\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - split_data
