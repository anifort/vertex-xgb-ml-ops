name: Xgb training
inputs:
- {name: dta_in_x_train, type: Dataset}
- {name: dta_in_y_train, type: Dataset}
- {name: dta_in_x_test, type: Dataset}
- {name: dta_in_y_test, type: Dataset}
outputs:
- {name: model, type: Model}
- {name: metrics_conf, type: ClassificationMetrics}
- {name: metrics_para, type: Metrics}
- {name: path, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'argparse' 'pandas' 'xgboost' 'numpy' 'sklearn' 'fsspec' 'gcsfs' 'kfp==1.8.9' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef xgb_training( \n    dta_in_x_train: Input[Dataset], \n   \
      \ dta_in_y_train: Input[Dataset],\n    dta_in_x_test: Input[Dataset],\n    dta_in_y_test:\
      \ Input[Dataset],\n    model: Output[Model],\n    metrics_conf: Output[ClassificationMetrics],\n\
      \    metrics_para: Output[Metrics]\n)  -> NamedTuple(\n    'ModelPathOut',\n\
      \    [\n      ('path', str)\n    ]):\n\n    import pandas as pd\n    import\
      \ xgboost as xgb\n    import numpy as np\n    from google.cloud import storage\n\
      \    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics\
      \ import roc_curve\n    import os\n\n    from collections import namedtuple\n\
      \n    ### Load data ###\n    x_train = pd.read_csv(dta_in_x_train.path, header=None)\n\
      \    y_train = pd.read_csv(dta_in_y_train.path, header=None)\n    x_test = pd.read_csv(dta_in_x_test.path,\
      \ header=None)\n    y_test = pd.read_csv(dta_in_y_test.path, header=None)\n\n\
      \    ### Build model ###\n    eval_set = [(x_train, y_train.values.ravel()),\
      \ (x_test, y_test.values.ravel())]\n    eval_metric = [\"auc\"]\n    bst = xgb.XGBClassifier(objective='reg:logistic')\n\
      \    bst.fit(x_train, y_train.values.ravel(), eval_set=eval_set, eval_metric=eval_metric)\n\
      \n    ### Create evaluation metrics ###\n        # Confusion matrix\n    pred\
      \ = bst.predict(x_train)\n    metrics_conf.log_confusion_matrix([\"0\", \"1\"\
      ], confusion_matrix(y_train.values.ravel(), pred).tolist())\n\n        # Additional\
      \ metrics\n    results = bst.evals_result()\n    auc = results['validation_0']['auc'][0]\n\
      \    metrics_para.log_metric(\"auc\", (auc))\n\n    ### Export model ###\n \
      \   os.makedirs(model.path, exist_ok=True)\n    bst.save_model(model.path+\"\
      /model.bst\")\n\n    output = namedtuple('ModelPathOut',\n        ['path'])\n\
      \    return output(model.path.replace('/gcs/', 'gs://'))\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - xgb_training
